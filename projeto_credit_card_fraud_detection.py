# -*- coding: utf-8 -*-
"""Projeto - Credit Card Fraud Detection.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1yNmrBnu-NwfeAmHQsr6erOo94-fkeV_j

#Projeto Data Science 1: Detecção de Fraudes com Cartão de Crédito

O conjunto de dados contém transações feitas por cartões de crédito em setembro de 2013 por titulares de cartões europeus.
Este conjunto de dados apresenta transações que ocorreram em dois dias, onde temos 492 fraudes em 284.807 transações. O conjunto de dados é altamente desequilibrado, a classe positiva (fraudes) é responsável por 0,172% de todas as transações.
Ele contém apenas variáveis ​​de entrada numéricas que são o resultado de uma transformação PCA. Infelizmente, devido a questões de confidencialidade, não podemos fornecer os recursos originais e mais informações básicas sobre os dados. Os recursos V1, V2,… V28 são os componentes principais obtidos com o PCA, os únicos recursos que não foram transformados com o PCA são 'Tempo' e 'Quantidade'. O recurso 'Tempo' contém os segundos decorridos entre cada transação e a primeira transação no conjunto de dados. O recurso 'Amount' é o Amount da transação, este recurso pode ser usado como exemplo de aprendizagem dependente de custos. O recurso 'Classe' é a variável de resposta e assume o valor 1 em caso de fraude e 0 em caso contrário.

Dada a razão de desequilíbrio de classe, recomendamos medir a precisão usando a área sob a curva de recuperação de precisão (AUPRC). A precisão da matriz de confusão não é significativa para a classificação não balanceada.

Fonte:https://www.kaggle.com/mlg-ulb/creditcardfraud?select=creditcard.csv

##Bibliotecas e Dados
"""

#Bibliotecas básicas
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

"""##Tratamento dos dados"""

df = pd.read_csv('/content/drive/MyDrive/Projetos python/Projeto 1: Credit Card Fraud Detection/creditcard.csv')


#Amount é o valor transacionado

"""##Análise de dados

##Pré-processamento

###Divisão entre Previsores e Classe
"""

len(df.columns)

x_df = df.iloc[:,:30].values
x_df

y_df = df.iloc[:,30:].values
y_df

"""###Escalonamento dos valores"""

from sklearn.preprocessing import StandardScaler
scaler_credit = StandardScaler()
x_df = scaler_credit.fit_transform(x_df)

x_df

"""###Fazer separação entre treinamento e teste"""

from sklearn.model_selection import train_test_split

X_treino, X_teste, y_treino, y_teste = train_test_split(x_df, y_df, test_size = 0.30)

X_teste.shape

y_treino.shape

"""##Processamento: Aplicação dos algoritmos

###Regressão Logística
"""

from sklearn.linear_model import LogisticRegression

logistic = LogisticRegression(max_iter=300)

logistic.fit(X_treino, y_treino)

logistic.intercept_

logistic.coef_

previsoes = logistic.predict(X_teste)
previsoes

y_teste

"""####Avaliação dos Modelos"""

from sklearn.metrics import accuracy_score, classification_report
accuracy_score(y_teste, previsoes)

from yellowbrick.classifier import ConfusionMatrix
cm = ConfusionMatrix(logistic)
cm.fit(X_treino, y_treino)
cm.score(X_teste, y_teste)

print(classification_report(y_teste, previsoes))





"""###SVM"""

from sklearn.svm import SVC

svm = SVC(kernel = 'linear')

svm.fit(X_treino, y_treino)

previsoes = svm.predict(X_teste)
previsoes

from sklearn.metrics import accuracy_score, classification_report
accuracy_score(y_teste, previsoes)

from yellowbrick.classifier import ConfusionMatrix
cm = ConfusionMatrix(svm)
cm.fit(X_treino, y_treino)
cm.score(X_teste, y_teste)

print(classification_report(y_teste, previsoes))

"""###Redes Neurais Artificiais - RNA"""

from sklearn.neural_network import MLPClassifier

X_treino.shape, y_treino.shape

(30+1)/2

#30 neurônios na camada entrada
#16 neurônios na camada oculta
#16 neurônios na camada oculta
# 1 #16 neurônios na camada de saída

rede_neural = MLPClassifier(verbose=True, max_iter=1000, tol=0.000010, hidden_layer_sizes=(16, 16))
rede_neural.fit(X_treino, y_treino)

previsoes = rede_neural.predict(X_teste)
previsoes

from sklearn.metrics import accuracy_score, classification_report
accuracy_score(y_teste, previsoes)

from yellowbrick.classifier import ConfusionMatrix
cm = ConfusionMatrix(rede_neural)
cm.fit(X_treino, y_treino)
cm.score(X_teste, y_teste)

print(classification_report(y_teste, previsoes))



"""##Resumo dos Modelos

###Resultado dos modelos

**Os modelos tiveram os seguintes resultados:**

Regressão Logística: 99,91%

SVM: 99,93%

Redes Neurais: 99,93%

###Validação cruzada
"""

from sklearn.model_selection import GridSearchCV
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.neural_network import MLPClassifier

from sklearn.model_selection import cross_val_score, KFold

resultados_logistica = []
resultados_svm = []
resultados_rede_neural = []

for i in range(30):
  print(i)
  kfold = KFold(n_splits=10, shuffle=True, random_state=i)

  logistica = LogisticRegression(max_iter=300)
  scores = cross_val_score(logistica, x_df, y_df, cv = kfold)
  resultados_logistica.append(scores.mean())

  svm = SVC(kernel = 'linear')
  scores = cross_val_score(svm, x_df, y_df, cv = kfold)
  resultados_svm.append(scores.mean())

  rede_neural = MLPClassifier(verbose=True, max_iter=1000, tol=0.000010, hidden_layer_sizes=(16, 16))
  scores = cross_val_score(rede_neural, x_df, y_df, cv = kfold)
  resultados_rede_neural.append(scores.mean())

resultados_rede_neural

resultados = pd.DataFrame({'Logistica': resultados_logistica,
                           'SVM': resultados_svm, 'Rede neural': resultados_rede_neural})
resultados

resultados.describe()

(resultados.std() / resultados.mean()) * 100

"""###Teste estatístico ANOVA"""

from scipy.stats import f_oneway

_, p = f_oneway(resultados_logistica, resultados_svm, resultados_rede_neural)
p

alpha = 0.05
if p <= alpha:
  print('Hipótese nula rejeitada. Dados são diferentes')
else:
  print('Hipótese alternativa rejeitada. Resultados são iguais')

resultados_algoritmos = {'accuracy': np.concatenate([resultados_logistica, resultados_svm, resultados_rede_neural]),
                         'algoritmo': ['logistica','logistica','logistica','logistica','logistica','logistica','logistica','logistica','logistica','logistica','logistica','logistica','logistica','logistica','logistica','logistica','logistica','logistica','logistica','logistica','logistica','logistica','logistica','logistica','logistica','logistica','logistica','logistica','logistica','logistica',
                          'svm','svm','svm','svm','svm','svm','svm','svm','svm','svm','svm','svm','svm','svm','svm','svm','svm','svm','svm','svm','svm','svm','svm','svm','svm','svm','svm','svm','svm','svm',
                          'rede_neural','rede_neural','rede_neural','rede_neural','rede_neural','rede_neural','rede_neural','rede_neural','rede_neural','rede_neural','rede_neural','rede_neural','rede_neural','rede_neural','rede_neural','rede_neural','rede_neural','rede_neural','rede_neural','rede_neural','rede_neural','rede_neural','rede_neural','rede_neural','rede_neural','rede_neural','rede_neural','rede_neural','rede_neural','rede_neural']}

resultados_df = pd.DataFrame(resultados_algoritmos)
resultados_df

from statsmodels.stats.multicomp import MultiComparison

compara_algoritmos = MultiComparison(resultados_df['accuracy'], resultados_df['algoritmo'])

teste_estatistico = compara_algoritmos.tukeyhsd()
print(teste_estatistico)

resultados.mean()