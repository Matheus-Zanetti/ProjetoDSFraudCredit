# -*- coding: utf-8 -*-
"""Projeto - Credit Card Fraud Detection.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1yNmrBnu-NwfeAmHQsr6erOo94-fkeV_j

#Projeto Data Science 1: Detecção de Fraudes com Cartão de Crédito

O conjunto de dados contém transações feitas por cartões de crédito em setembro de 2013 por titulares de cartões europeus.
Este conjunto de dados apresenta transações que ocorreram em dois dias, onde temos 492 fraudes em 284.807 transações. O conjunto de dados é altamente desequilibrado, a classe positiva (fraudes) é responsável por 0,172% de todas as transações.
Ele contém apenas variáveis ​​de entrada numéricas que são o resultado de uma transformação PCA. Infelizmente, devido a questões de confidencialidade, não podemos fornecer os recursos originais e mais informações básicas sobre os dados. Os recursos V1, V2,… V28 são os componentes principais obtidos com o PCA, os únicos recursos que não foram transformados com o PCA são 'Tempo' e 'Quantidade'. O recurso 'Tempo' contém os segundos decorridos entre cada transação e a primeira transação no conjunto de dados. O recurso 'Amount' é o Amount da transação, este recurso pode ser usado como exemplo de aprendizagem dependente de custos. O recurso 'Classe' é a variável de resposta e assume o valor 1 em caso de fraude e 0 em caso contrário.

Dada a razão de desequilíbrio de classe, recomendamos medir a precisão usando a área sob a curva de recuperação de precisão (AUPRC). A precisão da matriz de confusão não é significativa para a classificação não balanceada.

Fonte:https://www.kaggle.com/mlg-ulb/creditcardfraud?select=creditcard.csv

##Bibliotecas e Dados
"""

#Bibliotecas básicas
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

"""##Tratamento dos dados"""

df = pd.read_csv('/content/drive/MyDrive/Projetos python/creditcard.csv')
df.describe()


#Amount é o valor transacionado

"""##Análise de dados

##Pré-processamento

###Divisão entre Previsores e Classe
"""

len(df.columns)

x_df = df.iloc[:,:30].values
x_df

y_df = df.iloc[:,30:].values
y_df

"""###Escalonamento dos valores"""

from sklearn.preprocessing import StandardScaler
scaler_credit = StandardScaler()
x_df = scaler_credit.fit_transform(x_df)

x_df

"""###Fazer separação entre treinamento e teste"""

from sklearn.model_selection import train_test_split

X_treino, X_teste, y_treino, y_teste = train_test_split(x_df, y_df, test_size = 0.30)

X_teste.shape

y_treino.shape

"""##Processamento: Aplicação dos algoritmos

###Regressão Logística
"""

from sklearn.linear_model import LogisticRegression

logistic = LogisticRegression(max_iter=300)

logistic.fit(X_treino, y_treino)

logistic.intercept_

logistic.coef_

previsoes = logistic.predict(X_teste)
previsoes

y_teste

"""####Avaliação dos Modelos"""

from sklearn.metrics import accuracy_score, classification_report
accuracy_score(y_teste, previsoes)

from yellowbrick.classifier import ConfusionMatrix
cm = ConfusionMatrix(logistic)
cm.fit(X_treino, y_treino)
cm.score(X_teste, y_teste)

print(classification_report(y_teste, previsoes))





"""###SVM"""

from sklearn.svm import SVC

svm = SVC(kernel = 'linear')

svm.fit(X_treino, y_treino)

previsoes = svm.predict(X_teste)
previsoes

from sklearn.metrics import accuracy_score, classification_report
accuracy_score(y_teste, previsoes)

from yellowbrick.classifier import ConfusionMatrix
cm = ConfusionMatrix(svm)
cm.fit(X_treino, y_treino)
cm.score(X_teste, y_teste)

print(classification_report(y_teste, previsoes))

